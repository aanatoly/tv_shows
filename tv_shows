#!/usr/bin/python2

############################################
# Logging
############################################
import logging


def _init_log():
    name = 'tv_show'
    log = logging.getLogger(name)
    log.setLevel(logging.INFO)
    # log.setLevel(logging.DEBUG)
    h = logging.StreamHandler()
    f = logging.Formatter("%(name)s (%(funcName)s:%(lineno)d) :: %(message)s")
    # f = logging.Formatter("%(message)s")
    h.setFormatter(f)
    log.addHandler(h)
    return log

log = _init_log()

############################################
# Argument parsing
############################################
import argparse
desc = '''Looks up new opisodes of tv shows'''
p = argparse.ArgumentParser(description=desc)
p.add_argument("--debug", help="debug mode", action="store_true")
p.add_argument("-n", help="exact show name, eg 'Black Sails'",
               dest="name", metavar='NAME')
p.add_argument("-a", help="scan all shows in db", dest="all",
               action="store_true")
p.add_argument("-i", help="db info", dest="info",
               action="store_true")
p.add_argument("-s", help="chack available subtitles", dest="subtitles",
               action="store_true")
p.add_argument("-b", help="open links in a browser", dest="browser",
               action="store_true")
p.add_argument("-t", help="show trends and popular TV shows", dest="trends",
               action="store_true")

args = p.parse_args()
if args.debug:
    log.setLevel(logging.DEBUG)

log.debug("Args: %s", args)

############################################
# Imports
############################################
import subprocess as sp
from bs4 import BeautifulSoup
import re
import zlib
import datetime
import json
import textwrap
import string
import signal
import sys
import os
import urllib
import tempfile

############################################
# Config
############################################
uagent = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:11.0) ' + \
         'Gecko/20100101 Firefox/11.0'
config_file = '~/.tv_shows'
config_file_real = os.path.expanduser(config_file)

default_xconf = {
    'browser': 'firefox-bin',
    'torrent_dir': '~/Downloads/torrents',
    'tvs': {
        'Black Sails': 's01e05',
        'Elementary': 's02e15',
    }
}


def config_read():
    try:
        text = open(config_file_real, 'r').read()
    except:
        config_write_default("does not exists")
        exit(1)

    try:
        xconf = eval(text)
        k1 = sorted(xconf.keys())
        k2 = sorted(default_xconf.keys())
        if k1 != k2:
            raise Exception("wrong format")
    except:
        config_write_default("has wrong format", text)
        exit(1)

    ntvs = {}
    for tv in xconf['tvs']:
        ntv = string.capwords(tv)
        ntvs[ntv] = xconf['tvs'][tv]
    xconf['tvs'] = ntvs

    return xconf


def pprint_dict(d):
    return json.dumps(d, indent=4, sort_keys=True) + '\n'


def config_write(xconf):
    open(config_file_real, 'w').write(pprint_dict(xconf))


def config_write_default(msg, old_config=None):
    print "Config file %s %s." % (config_file, msg)
    if old_config:
        print "It's saved as %s" % (config_file + ".bak",)
        open(config_file_real + ".bak", 'w').write(old_config)
    print "New one was created, please edit it and run script again"
    config_write(default_xconf)


def update_tvs_from_dl(xconf, tvs):
    files = []
    torrent_dir = os.path.expanduser(xconf['torrent_dir'])
    for (dirpath, dirnames, filenames) in os.walk(torrent_dir):
        files.extend(filenames)
        files.extend(dirnames)
    files = [f.replace("'", "") for f in files]
    files = [f.replace(".", " ") for f in files]
    files = [' '.join(f.split()) for f in files]

    for tv in tvs:
        rtv = '(?i)' + tv.replace("'", "") + '.*(S\d\dE\d\d).*'
        for f in files:
            m = re.search(rtv, f)
            if not m:
                continue
            ep_last = m.group(1).lower()
            if ep_last > tvs[tv]:
                log.debug('update %s to %s', tv, ep_last)
                tvs[tv] = ep_last


############################################
# Subtitles
############################################
sub_site = 'http://www.subtitleseeker.com'


def update_subtitles(name, tv):
    name = name.replace("'", "")
    update_subtitles_tv(name, tv)
    update_subtitles_episodes(name, tv)


def update_subtitles_tv(name, tv):
    global re_subtitles

    log.debug('%s', name)
    url = sub_site + '/search/TV_TITLES/' + name
    try:
        html = wget(url, sub_site, uagent)
    except:
        print >> sys.stderr, '\n', sub_site, 'is unavailable'
        return

    soup = BeautifulSoup(html)
    for d in soup.find_all('div', attrs={'class': 'boxRows'}):
        try:
            a = d.div.a
            t = string.capwords(a.text).replace("'", "")
        except:
            continue
        log.debug("title '%s', href '%s'", t, a['href'])
        if t != name:
            continue
        tv['sub_url'] = a['href']
        break


re_subtitles = None


def update_subtitles_episodes(name, tv):
    global re_subtitles

    log.debug('%s', name)
    url = sub_site + '/search/TV_EPISODES/' + name
    try:
        html = wget(url, sub_site, uagent)
    except:
        print >> sys.stderr, '\n', sub_site, 'is unavailable'
        return

    if not re_subtitles:
        r = '(?i)(?P<name>.*)\s+\(\d\d\d\d\)\s+(?P<ep>S\d\dE\d\d)\s+' + \
            '(?P<sno>\d+)?\s+Sub'
        re_subtitles = re.compile(r)

    soup = BeautifulSoup(html)
    eps = tv['eps']
    for d in soup.find_all('div', attrs={'class': 'boxRows'}):
        t = string.capwords(d.text).replace("'", "")
        # log.debug("%s", t)
        m = re_subtitles.match(t)
        if not m:
            continue
        log.debug("%s %s %s", m.group('name'), m.group('ep'), m.group('sno'))
        xname = string.capwords(m.group('name'))
        xep = m.group('ep').lower()
        xsno = m.group('sno')

        if name != xname:
            continue
        if xep not in eps:
            eps[xep] = new_ep()
        eps[xep]['has_sub'] = (xsno != '' and xsno != '0')


############################################
# Torrents
############################################
re_torrents = None
kat_site = 'http://kickass.to'

def update_torrents(name, tv):
    global re_torrents

    log.debug('%s', name)
    name = name.replace("'", "")
    url = kat_site + '/usearch/' + name.replace(' ', '%20') + \
        '%20category%3Atv/'
    opts = '?field=time_add&sorder=desc'
    html = wget(url, kat_site) + wget(url + opts, kat_site)
    tv['torrent_url'] = url + opts

    if not re_torrents:
        re_torrents = '(?i)(?P<name>.*)\s+(?P<ep>S\d\dE\d\d)'
        re_torrents = re.compile(re_torrents)

    eps = tv['eps']
    soup = BeautifulSoup(html)
    for d in soup.find_all('div', attrs={'class': 'torrentname'}):
        t = string.capwords(d.text).replace("'", "")
        # log.debug("%s", t)
        m = re_torrents.match(t)
        if not m:
            continue
        xname = string.capwords(m.group('name')).replace("'", "")
        xep = m.group('ep').strip().lower()
        # drop bogus episods, like sXXe99
        if int(xep[-2:]) > 90:
            continue
        if name != xname:
            continue
        log.debug('%s %s', xname, xep)
        if xep not in eps:
            eps[xep] = new_ep()
        eps[xep]['has_torrent'] = True


############################################
# Trends
############################################
def add_trends(trends, name, se):
    name = ' '.join(name.split())
    se = se.upper()
    log.debug('Name: %s', name)
    log.debug('EP:   %s', se)
    key = name.lower()
    if key not in trends:
        trends[key] = {'name': name, 'se': se, 'no': 1}
    else:
        trends[key]['no'] += 1
        if trends[key]['se'] < se:
            trends[key]['se'] = se


def get_trends():
    url = kat_site + '/tv/'
    html = ''
    for p in ['', '2', '3', '4']:
        html += wget(url + p, kat_site)

    # html = open('tv2.htm', 'r').read()
    soup = BeautifulSoup(html)
    trends = {}
    for d in soup.find_all('a', attrs={'class': 'cellMainLink'}):
        t = d.text.replace("'", "")
        log.debug('Torrent name: "%s"', t)
        t = t.replace(".", " ")
        t = re.sub('(?i)HDTV.*', '', t)

        reg = '(?P<name>.+?)(?P<se>S\d\dE\d\d)'
        m = re.match(reg, t)
        if m:
            add_trends(trends, m.group('name'), m.group('se'))
            continue

        reg = '(?P<name>.+?)(?P<s>S\d\d)E\d+-(?P<e>E\d+)'
        m = re.match(reg, t)
        if m:
            add_trends(trends, m.group('name'), m.group('s') + m.group('e'))
            continue

        reg = '(?P<name>.+?)(E\d+-)?(?P<e>E\d+)'
        m = re.match(reg, t)
        if m:
            add_trends(trends, m.group('name'), m.group('e'))
            continue

    score = []
    for key in trends:
        score.append((trends[key]['no'],
                      trends[key]['name'],
                      trends[key]['se']))
    score = sorted(score, key=lambda k: (-k[0], k[1]))
    mlen = str(max([len(t[1]) for t in score]))
    fmt = '%-' + mlen + 's  %-6s  %s'
    log.debug('fmt %s', fmt)
    print '\033[1m' + fmt % ('Name', 'Ep', 'Refs') + '\033[0m'
    for t in score:
        print fmt % (t[1], t[2], str(t[0]))

############################################
# Air dates
############################################
re_air_dates = None
air_dates_site = 'http://www.tvrage.com'


def air_dates_search_tv(name):
    s = urllib.urlencode({'search': name})
    url = '%s/search.php?%s' % (air_dates_site, s)
    html = wget(url, air_dates_site)
    return html

    
def air_dates_get_tv_url(name, details, html):
    soup = BeautifulSoup(html)
    for d in soup.find_all('h2'):
        lname = d.a.string
        tmp = lname.split()
        # log.debug("tmp %s", tmp)
        if tmp[-1][0] == '(' and tmp[-1][-1] == ')':
            ldetails = tmp[-1][1:-1]
            lname = ' '.join(tmp[0:-1])
        else:
            ldetails = ''
        lurl = d.a['href']
        log.debug('name "%s", details "%s", url "%s"', lname, ldetails, lurl)
        if name.lower() != lname.lower():
            continue
        if details is None:
            return lurl
        if details.lower() == ldetails.lower():
            return lurl
    return ''

    
def air_dates_parse_dates(eps, html):
    global re_air_dates
    
    soup = BeautifulSoup(html)
    if not re_air_dates:
        r = '(?i)\d+\s+(?P<s>\d+)x(?P<e>\d+)\s+(?P<d>\S+)'
        re_air_dates = re.compile(r)

    for d in soup.find_all('tr', attrs={'id': 'brow'}):
        t = ' '.join(d.text.split())
        m = re_air_dates.match(t)
        if not m:
            continue
        ep = 's%02de%02d' % (int(m.group('s')), int(m.group('e')))
        try:
            d = datetime.datetime.strptime(m.group('d'), '%d/%b/%Y')
        except:
            d = None
        log.debug("%s %s", ep, d)
        if ep not in eps:
            eps[ep] = new_ep()
        eps[ep]['air_date'] = d

        
def update_air_dates(name, tv):
    html = air_dates_search_tv(name)
    url = air_dates_get_tv_url(name, None, html)
    if not url:
        return
    html = wget(url + '/episode_list/all', air_dates_site)
    air_dates_parse_dates(tv['eps'], html)


############################################
# Misc
############################################
def wget(url, referer=None, uagent=None):
    dummy, tmp = tempfile.mkstemp()
    cmd = [
        'wget', '--timeout=10', '--tries=2', '--max-redirect=1',
        '-k', '-q', '-O', tmp
    ]
    if referer:
        cmd += ['--referer=' + referer]
    if uagent:
        cmd += ['--user-agent=' + uagent]
    cmd += [url]
    log.debug('wget %s', cmd)
    sp.check_output(cmd, stderr=open('/dev/null', 'w'))
    html = open(tmp, 'r').read()
    os.remove(tmp)
    try:
        d = zlib.decompressobj(16+zlib.MAX_WBITS)
        html = d.decompress(html)
    except:
        pass
    return html

    
def new_tv_show():
    tv = dict()
    tv['eps'] = {}
    tv['torrent_url'] = ''
    tv['sub_url'] = ''
    tv['dl_ep'] = 's00e00'
    return tv


def new_ep():
    ep = dict()
    ep['air_date'] = None
    ep['has_torrent'] = False
    ep['has_sub'] = False
    return ep


def update_tv_show(name, tv):
    log.debug('%s', name)
    update_air_dates(name, tv)
    update_torrents(name, tv)
    if args.subtitles:
        update_subtitles(name, tv)


def print_tv_show(tv):
    msg_dl = tv['dl_ep']
    if msg_dl == 's00e00':
        msg_dl = ''

    # find new episodes
    eps = tv['eps']
    ep_ids = [ep_id for ep_id in sorted(eps) if ep_id > tv['dl_ep']]
    log.debug('eps %s', ep_ids)
    if not ep_ids:
        return (msg_dl, '')

    # find new episodes with torrents
    ss = []
    for ep_id in ep_ids:
        if not eps[ep_id]['has_torrent']:
            continue
        s = ep_id
        if eps[ep_id]['has_sub']:
            s += ' + subs'
        ss.append(s)
    if ss:
        if args.browser:
            if tv['torrent_url']:
                sp.Popen([xconf['browser'], tv['torrent_url']],
                         stderr=open('/dev/null', 'r'))
            if tv['sub_url']:
                sp.Popen([xconf['browser'], tv['sub_url']],
                         stderr=open('/dev/null', 'r'))
        return (msg_dl, ', '.join(ss))

    # find date of the next episode
    today = datetime.datetime.today()
    # msg_next = 'Next ' + ep_ids[0]
    msg_next = ''
    d = eps[ep_ids[0]]['air_date']
    if d:
        # msg_next += ' at ' + str(d.date())
        days = (d - today).days + 1
        if days > 0:
            msg_next += 'in ' + str(days) + ' days'
        else:
            msg_next += 'soon'
    return (msg_dl, msg_next)


def signal_handler(signal, frame):
    print
    sys.exit(0)

############################################
# Main
############################################
def main():
    signal.signal(signal.SIGINT, signal_handler)

    xconf = config_read()

    if args.info:
        print config_file
        print pprint_dict(xconf)
        exit(0)

    if args.trends:
        get_trends()
        exit(0)

    tvs = {}

    nlen = 0
    if args.name:
        name = args.name
        name = string.capwords(name)
        nlen = len(name)
        tv = new_tv_show()
        tvs[name] = tv
    elif args.all:
        update_tvs_from_dl(xconf, xconf['tvs'])
        config_write(xconf)
        for name in sorted(xconf['tvs']):
            if nlen < len(name):
                nlen = len(name)
            tv = new_tv_show()
            tv['dl_ep'] = xconf['tvs'][name]
            tvs[name] = tv

    if not tvs:
        exit(0)

    nlen += 3
    afmt = '%-' + str(nlen) + 's' + '%-9s%s'
    indent = ' ' * (nlen + 9)
    tw = textwrap.TextWrapper(width=78,
                              replace_whitespace=False,
                              subsequent_indent=indent)

    print "\033[1m" + (afmt % ('TV', 'Old', 'New')) + "\033[0m"
    for name in sorted(tvs):
        print name, " ",
        sys.stdout.flush()
        update_tv_show(name, tvs[name])
        msg = afmt % ((name,) + print_tv_show(tvs[name]))
        msg = "\033[" + str(nlen) + "D" + tw.fill(msg)
        print msg


if __name__ == '__main__':
    main()
